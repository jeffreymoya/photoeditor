# Single task template for LLM-executable work
# Copy to tasks/<area>/TASK-<id>-<slug>.task.yaml and replace every REPLACE placeholder.
# Delete comment lines you have satisfied, but keep all YAML keys so automation stays stable.
# If the effort feels wider than one independently shippable change, stop and split it into
# multiple task files before continuing.

schema_version: "1.1"  # Schema 1.1 requires validation section and non-empty plan outputs
id: TASK-0000                    # REPLACE: stable ID (e.g., TASK-0123)
title: "REPLACE: action-oriented title"
status: draft                    # draft | todo | in_progress | blocked | completed — stay draft until clarifications resolved
blocked_reason: null             # REQUIRED when status=blocked; explain the external dependency
priority: P1                     # P0 | P1 | P2
area: backend                    # backend | mobile | shared | infra | docs | ops | other
unblocker: false                 # true if this task unblocks other work (task picker prioritizes it; Python CLI rollout in docs/proposals/task-workflow-python-refactor.md)
order: null                      # Optional: execution order for orchestration
blocked_by: []                   # Hard execution blockers (task cannot START until these complete)
depends_on: []                   # Informational dependencies (outputs needed but not blocking execution); if the dependency is draft, add it to blocked_by instead
agent_completion_state: {}       # Optional: managed by task-runner; tracks completed agents for resumption (do not edit manually)

clarifications:
  outstanding:
    - REPLACE: open question, ambiguity, or standards gap to resolve before moving to todo; remove this list when empty
  evidence_path: "REPLACE: docs/evidence/tasks/TASK-0000-clarifications.md"  # REQUIRED before transitioning draft -> todo; keep history even if list is empty

description: >-
  REPLACE: Provide concise context (2–5 sentences). Include business value, constraints,
  and any assumptions. Link to prior work so the task is self-contained.

outcome: >-
  REPLACE: State the measurable end state. Describe what success looks like without listing steps.

scope:
  in:
    - REPLACE: files, modules, or behaviours in scope
  out:
    - REPLACE: explicit exclusions that prevent scope creep

context:
  affected_packages: [backend]    # Adjust packages to drive test automation; leave [] if none
  standards_tier: backend         # backend | mobile | shared | infra | docs | ops
  related_docs:
    - standards/global.md
    - standards/AGENTS.md
    - standards/testing-standards.md
    - REPLACE: standards/<tier>-tier.md
    - REPLACE: docs/design/<reference>.md
  repo_paths:
    - REPLACE: approximate file path or directory touched (refresh with the exact files before closing the task)
  dependencies: []                # List external services/packages or remove if unused

environment:
  os: ubuntu-22.04
  runtimes:
    node: "20.x"                  # Update or remove runtimes that do not apply
  tools:
    - name: pnpm
      version: "8.x"
  data: []                        # Optional sample data or fixtures required

constraints:
  approvals_required: false
  sandbox:
    filesystem: workspace-write
    network: enabled
  coding_guidelines:
    - Keep diffs minimal and focused on the described scope.
    - Follow repository standards referenced above.
  prohibited:
    - No secrets or credentials in source control.

# Plan steps: declare who executes, what goes in/out, and what proves completion.
# Required keys per step: actor (agent|human), inputs, outputs, definition_of_done, estimate (S|M|L)
# Cite the exact standards clause (file + heading slug) that governs the work inside each step.
plan:
  - id: 1
    title: Understand baseline and standards
    details: >-
      REPLACE: audit current implementation, review cited standards, capture any gaps that require a standards change request.
      Reference the specific rule you are validating (e.g., standards/backend-tier.md#service-layer-boundaries).
    actor: agent                 # agent | human — who executes this step
    inputs:                      # REPLACE: files/docs to read or preconditions
      - REPLACE: existing spec or code path under review
    outputs:                     # REPLACE: tangible artifacts from this step
      - REPLACE: docs/evidence/standards-review.md (notes citing governing clause)
    definition_of_done:
      - REPLACE: Standards alignment notes reference standards/<tier>-tier.md#<heading> and standards/typescript.md#<heading> with findings/outcome.
    estimate: S                  # S | M | L — rough effort/timebox
    expected_files_touched: []
  - id: 2
    title: Implement change
    details: >-
      REPLACE: describe the core implementation approach and call out which standards clause guides the design (e.g., standards/typescript.md#analyzability or standards/backend-tier.md#domain-service-layer).
      Verify anchor headings exist in referenced standards files before citing.
    actor: agent
    inputs: []
    outputs:  # REPLACE_WITH_DELIVERABLES: List all files created/modified (e.g., src/domain/job.ts, tests/job.test.ts)
      - REPLACE: primary implementation file(s)
      - REPLACE: test file(s) or evidence updates
    definition_of_done:
      - REPLACE: Implementation satisfies standards/<tier>-tier.md#<heading>; mention evidence path proving compliance.
    estimate: M
    expected_files_touched:
      - REPLACE: primary file(s)
  - id: 3
    title: Validate and document
    details: >-
      REPLACE: describe evidence collection and documentation handoff; automated test suites run via agents. Cite the QA requirement you are satisfying (e.g., standards/testing-standards.md#coverage-expectations).
    actor: agent
    inputs: []
    outputs:  # REPLACE_WITH_DELIVERABLES: Evidence artifacts, test reports, or documentation files
      - REPLACE: docs/evidence/tasks/TASK-0000-clarifications.md (validation notes)
    definition_of_done:
      - REPLACE: Validation artifacts stored and cross-referenced with standards/testing-standards.md#<heading> thresholds.
    estimate: S
    expected_files_touched:
      - REPLACE: docs or evidence paths

# Validation commands must be executable via standards/qa-commands-ssot.md pipeline.
# Reference coverage thresholds from standards/testing-standards.md (SSOT: ≥70% lines, ≥60% branches).
# Tier-specific overrides (if any) are documented in standards/<tier>-tier.md.
# See docs/templates/validation-section-examples.md for copy-paste examples per package.
validation:
  pipeline:
    - command: pnpm turbo run lint:fix --filter=@photoeditor/REPLACE_PACKAGE
      description: Auto-fix linting issues in REPLACE_PACKAGE package
    - command: pnpm turbo run qa:static --filter=@photoeditor/REPLACE_PACKAGE
      description: Run static analysis (typecheck + lint) on REPLACE_PACKAGE
    - command: pnpm turbo run test --filter=@photoeditor/REPLACE_PACKAGE
      description: Run unit tests for REPLACE_PACKAGE package
    - command: pnpm turbo run test:coverage --filter=@photoeditor/REPLACE_PACKAGE
      description: Run tests with coverage reporting to verify thresholds (≥70% lines, ≥60% branches per standards/testing-standards.md)
  manual_checks: []  # Add manual verification steps if automation cannot cover; prefer pipeline commands

acceptance_criteria:
  must:
    - REPLACE: objective behaviour tied to the standards cited (include data, UX, or API expectations)
    - REPLACE: measurable signal proving completion (e.g., log entry, metric threshold, UI output)
  quality_gates:
    - Affected standards references remain satisfied; note any deviations and link the follow-up standards change request.
    - No lint/type errors in affected packages.


artifacts:
  - path: REPLACE: docs/evidence/<artifact>.json
    description: REPLACE: what the artifact demonstrates

deliverables:
  - REPLACE: primary source file(s)
  - REPLACE: test file(s)
  - REPLACE: documentation or evidence updates

risks:
  - description: REPLACE: meaningful risk (e.g., performance regression, contract drift)
    mitigation: REPLACE: how it will be detected/mitigated (tests, flags, monitoring)
